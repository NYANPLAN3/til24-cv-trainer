{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import fiftyone as fo\n",
    "import fiftyone.utils.random as four\n",
    "import fiftyone.utils.iou as foui\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "from tilcvtrainer import JSONLImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../data/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.delete_dataset(\"til24cvraw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importer = JSONLImporter(dataset_dir)\n",
    "if fo.dataset_exists(\"til24cvraw\"):\n",
    "    dataset = fo.load_dataset(\"til24cvraw\")\n",
    "else:\n",
    "    dataset = fo.Dataset.from_importer(\n",
    "        importer, name=\"til24cvraw\", persistent=True, overwrite=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel all detections to UFO (lol)\n",
    "view: fo.DatasetView = dataset.set_field(\n",
    "    \"ground_truth.detections\", F(\"detections\").map(F().set_field(\"label\", \"UFO\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = F(\"ground_truth.detections\").length()\n",
    "foui.compute_max_ious(dataset, \"ground_truth\")\n",
    "\n",
    "# The `(min, max)` number of predictions per sample\n",
    "print(dataset.bounds(num_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.bounds(F(\"ground_truth.detections.max_iou\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits\n",
    "four.random_split(dataset, {\"train\": 0.98, \"val\": 0.02}, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in (\"train\", \"val\"):\n",
    "    v: fo.DatasetView = view.match_tags(split)\n",
    "    v.export(\n",
    "        export_dir=\"data/til24ufo\",\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        label_field=\"ground_truth\",\n",
    "        split=split,\n",
    "        classes=[\"UFO\"],\n",
    "        export_media=True,\n",
    "        include_path=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict YOLO on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone.utils.ultralytics import (\n",
    "    FiftyOneYOLODetectionModel,\n",
    "    FiftyOneYOLODetectionModelConfig,\n",
    ")\n",
    "from ultralytics import YOLO\n",
    "from functools import partial\n",
    "\n",
    "# Workaround to set confidence level...\n",
    "yolo = YOLO(\n",
    "    \"/workspaces/til24-cv-trainer/runs/detect/e256-e128ft-v3/weights/best.pt\",\n",
    "    task=\"detection\",\n",
    ")\n",
    "wrapped = partial(\n",
    "    yolo.predict, conf=0.05, iou=0.0, imgsz=1536, half=True, agnostic_nms=True\n",
    ")\n",
    "mcfg = FiftyOneYOLODetectionModelConfig({\"model\": wrapped})\n",
    "model = FiftyOneYOLODetectionModel(mcfg)\n",
    "\n",
    "# model = convert_ultralytics_model(\n",
    "#     YOLO(\n",
    "#         \"/workspaces/til24-cv-trainer/runs/detect/e256-e128ft-v3/weights/best.pt\",\n",
    "#         task=\"detection\",\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.apply_model(model, label_field=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = view.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval_predictions\",\n",
    ")\n",
    "results.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Caption Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone.core.patches import PatchesView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats: PatchesView = dataset.to_patches(\"ground_truth\")\n",
    "pats.untag_samples([\"train\", \"val\"])\n",
    "four.random_split(pats, {\"train\": 0.95, \"val\": 0.05}, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dirs = dict(\n",
    "    train=\"../data/til24id/train\",\n",
    "    val=\"../data/til24id/val\",\n",
    ")\n",
    "splits = (\"train\", \"val\")\n",
    "padding = 0.5, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, p in zip(splits, padding):\n",
    "    v: fo.DatasetView = pats.match_tags(split)\n",
    "    v.export(\n",
    "        export_dir=export_dirs[split],\n",
    "        export_media=True,\n",
    "        abs_paths=False,\n",
    "        label_field=\"ground_truth\",\n",
    "        alpha=p,\n",
    "        image_format=\".png\",\n",
    "        dataset_type=fo.types.FiftyOneImageClassificationDataset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in (\"train\", \"val\"):\n",
    "    tmp_ds = fo.Dataset.from_dir(\n",
    "        dataset_dir=export_dirs[split],\n",
    "        dataset_type=fo.types.FiftyOneImageClassificationDataset,\n",
    "    )\n",
    "    tmp_ds.export(\n",
    "        export_dir=export_dirs[split],\n",
    "        export_media=False,\n",
    "        abs_paths=True,\n",
    "        dataset_type=fo.types.CSVDataset,\n",
    "        fields={\"ground_truth.label\": \"title\", \"filepath\": \"filepath\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/workspaces/til24-cv-trainer/data/til24id/train/labels.csv\")\n",
    "val_df = pd.read_csv(\"/workspaces/til24-cv-trainer/data/til24id/val/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\n",
    "    \"/workspaces/til24-cv-trainer/data/til24id/train/labels.csv\", index=False, sep=\"\\t\"\n",
    ")\n",
    "val_df.to_csv(\n",
    "    \"/workspaces/til24-cv-trainer/data/til24id/val/labels.csv\", index=False, sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noised Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.contrib.concurrent import process_map\n",
    "import tqdm.notebook\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [\n",
    "    # A.Blur(p=0.01),\n",
    "    # A.MedianBlur(p=0.01),\n",
    "    A.RandomBrightnessContrast(p=0.7, contrast_limit=(0.0, 0.3), brightness_limit=0),\n",
    "    A.AdvancedBlur(\n",
    "        p=0.4, blur_limit=(3, 17), noise_limit=(0.0, 2.0), beta_limit=(0.0, 4.0)\n",
    "    ),\n",
    "    A.MotionBlur(p=0.4, blur_limit=(3, 17)),\n",
    "    # A.RandomGamma(p=0.0),\n",
    "    # A.ToGray(p=0.0),\n",
    "    A.ImageCompression(p=0.6, quality_lower=20, quality_upper=70),\n",
    "    A.CLAHE(p=0.25),\n",
    "    A.GaussNoise(p=0.5, per_channel=True, var_limit=(1000.0, 5000.0)),\n",
    "    A.ISONoise(p=0.5, intensity=(0.1, 0.5), color_shift=(0.03, 0.06)),\n",
    "]\n",
    "augment = A.Compose(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = \"/workspaces/til24-cv-trainer/data/raw/images\"\n",
    "out_dir = \"/workspaces/til24-cv-trainer/data/raw/augmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(out_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def augment_one(pth):\n",
    "    img = cv2.imread(str(pth))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    aug = augment(image=img)[\"image\"]\n",
    "    aug = cv2.cvtColor(aug, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(str(Path(out_dir) / pth.name), aug)\n",
    "\n",
    "\n",
    "nprocs = os.cpu_count()\n",
    "pths = list(Path(im_dir).glob(\"*.jpg\"))\n",
    "_ = process_map(\n",
    "    augment_one, pths, tqdm_class=tqdm.notebook.tqdm, max_workers=nprocs, chunksize=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open(\"/workspaces/til24-cv-trainer/data/raw/images/image_129.jpg\")\n",
    "\n",
    "\n",
    "def _wrap(aug):\n",
    "    return lambda im: Image.fromarray(aug(image=np.array(im))[\"image\"])\n",
    "\n",
    "\n",
    "a = _wrap(A.ISONoise(p=1.0))\n",
    "\n",
    "a(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
